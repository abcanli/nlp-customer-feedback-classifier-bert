ğŸ§  NLP Customer Feedback Classifier (BERT + ML Baseline)

This project builds a complete end-to-end NLP pipeline for classifying SaaS customer feedback into four actionable categories:

bug_report
feature_request
praise
cancellation_risk
It contains both:

âœ” TF-IDF + Logistic Regression (baseline)
âœ” Fine-tuned DistilBERT transformer model

allowing direct comparison between classical ML and modern transformer-based NLP.

The project is structured exactly like a real-world workflow used in Product Analytics, Customer Experience (CX), and NLP/ML teams.

ğŸš€ Key Features

Synthetic SaaS feedback dataset (balanced across 4 categories)

Complete preprocessing pipeline:
text cleaning
normalization
label encoding
train/val/test split
Baseline model: TF-IDF + Logistic Regression
Transformer model: DistilBERT fine-tuning

Evaluation tools:
Accuracy, Precision, Recall, F1-score
Confusion matrices
Baseline vs BERT comparison plots

Explainability:
LIME (baseline)
SHAP/Captum recommendations (BERT)
Streamlit-based interactive demo UI
Fully reproducible, production-style project structure

Works on CPU or GPU

ğŸ§± Project Structure

nlp-customer-feedback-classifier-bert/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ sample_raw_feedback.csv
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ processed_feedback.pkl
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_eda.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ train_baseline.py
â”‚   â”œâ”€â”€ train_bert.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”œâ”€â”€ explain.py
â”‚   â””â”€â”€ generate_synthetic_feedback.py
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ baseline/
â”‚   â””â”€â”€ bert/
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ metrics/
â”‚   â”œâ”€â”€ plots/
â”‚   â”‚   â””â”€â”€ model_comparison.png
â”‚   â””â”€â”€ explainability/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ“Š Dataset

The project uses a synthetic SaaS feedback dataset containing:
feedback_id
feedback_text
label
Labels include:
bug_report
feature_request
praise
cancellation_risk

You can replace this dataset with your own data from:
Zendesk
Intercom
Freshdesk
CRM exports
App reviews
NPS comments
Support tickets

ğŸ§ª Synthetic Dataset Generator

The original toy dataset had only 60 rows.
To create a more realistic training environment, the repo includes a synthetic dataset generator that expands it to:

â†’ 600 samples (150 per class)

Run:
python src/generate_synthetic_feedback.py

This will:
Backup original CSV â†’
data/raw/sample_raw_feedback_original_backup.csv

Generate a new balanced dataset â†’
data/raw/sample_raw_feedback.csv

Classes generated:

bug_report
feature_request
praise
cancellation_risk

ğŸš€ Full Pipeline (Preprocess â†’ Train â†’ Evaluate â†’ Demo)
1) Preprocess dataset
python src/preprocess.py

2) Train baseline model
python src/train_baseline.py

3) Train DistilBERT model
python src/train_bert.py

4) Evaluate both models
python src/evaluate.py


Outputs include:
Confusion matrices
Performance metrics
Class-level reports
Baseline vs BERT comparison plot

5) Run explainability
python src/explain.py

ğŸ‘©â€ğŸ’» Streamlit Demo App
Launch the interactive classification UI:
streamlit run app.py

Then open:
ğŸ‘‰ http://localhost:8501

You can test feedback like:

Example Feedback	Expected Label
â€œThe app crashes when I export data.â€	bug_report
â€œCan you add a dark mode option?â€	feature_request
â€œWe might cancel if downtime continues.â€	cancellation_risk
â€œGreat UI and excellent performance!â€	praise

ğŸ§ª Model Overview

1ï¸âƒ£ Baseline â€” TF-IDF + Logistic Regression
Fast to train
Highly interpretable
Strong performance
Saved under models/baseline/

2ï¸âƒ£ DistilBERT â€” Fine-Tuned Transformer
Context-aware
Handles complex expressions
Typically highest accuracy
Saved under models/bert/

ğŸ“Š Model Comparison (Baseline vs BERT)
<p align="center"> <img src="https://raw.githubusercontent.com/abcanli/nlp-customer-feedback-classifier-bert/main/nlp-customer-feedback-classifier-bert/outputs/plots/model_comparison.png" width="500"> </p>

âš™ï¸ Installation
git clone https://github.com/abcanli/nlp-customer-feedback-classifier-bert.git
cd nlp-customer-feedback-classifier-bert
python -m venv venv
venv\Scripts\activate  # on Windows
pip install -r requirements.txt

ğŸ“ˆ Typical Performance
Model	F1 Score	Notes
TF-IDF + Logistic Regression	0.85â€“0.90	Strong baseline
DistilBERT	0.90â€“0.95	Best-performing

ğŸ§© Future Work (Extend This Project)
Deploy BERT via FastAPI REST endpoint
Add SHAP explainability
Add human-in-the-loop feedback loop
Serve as a cloud function / Lambda
Build a full Product Analytics dashboard

ğŸ‘¤ Author
Ali Berk CanlÄ±
NLP/ML Analyst â€¢ Data Product Analyst
ğŸ”— LinkedIn: https://www.linkedin.com/in/aliberkcanlÄ±
ğŸ”— GitHub: https://github.com/abcanli
